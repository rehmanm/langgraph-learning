{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ed345-2276-411a-b164-6c4e49a0865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph langchain[google-genai]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec15a7a-a7ff-45b6-a2a3-f7ba0cfd9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mamals\", name = \"Model\")]\n",
    "messages.append(HumanMessage(content = f\"Yes you are right\", name = \"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c7930-08a7-44e2-a0fb-ea8e176aaefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81babd57-31de-4afd-9958-56b5592431c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "#from langchain.chat_models import init_chat_model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.0) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4db164-e549-45b5-8971-54d74f529a47",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def add(x: float, y:float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    " \n",
    "def subtract(x: float, y:float) -> float:\n",
    "    \"\"\"Subtract 'x' and 'y'.\"\"\"\n",
    "    return x - y\n",
    "\n",
    "\n",
    "def multiply(x: float, y:float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "\n",
    "def divide(x: float, y:float) -> float:\n",
    "    \"\"\"Divide 'x' and 'y'.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add, subtract, multiply, divide, exponentiate])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7132edbe-765c-4434-bca8-64c17bae0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    \"\"\"You are an helpful assistant tasked with performing arithmetic on a set of inputs.\n",
    "    \n",
    "    ----\n",
    "    User: 2 divide 3\n",
    "    AI: The answer is 0.66\n",
    "    \n",
    "    User: 20 divide -7\n",
    "    AI: The answer is -2.85\n",
    "    \n",
    "    User: 20 multiply 7\n",
    "    AI: The answer is 140.00    \n",
    "    \n",
    "    ----    \n",
    "    \n",
    "    \"\"\"\n",
    ") \n",
    "\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": llm_with_tools.invoke([sys_message] + state[\"messages\"])}\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([add, subtract, multiply, divide, exponentiate]))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e0077-e751-4388-b043-7d7a272b2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "messages = graph.invoke({\n",
    "    \"messages\": HumanMessage(content = \"What is 2 ** 3\")\n",
    "}, config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d8a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = graph.invoke({\n",
    "    \"messages\": HumanMessage(content = \"Add that to 7\")\n",
    "}, config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8168460d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
