{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf9c1c-c668-48fc-8cc9-3216fcb2ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph langchain_google_genai wikipedia pyppeteer certifi python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc61f4-8219-4156-9c43-73f71a2996c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66efb292-7796-429a-99f3-6d91eed738e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c4a6c-05a2-43df-86f6-ef574cbfbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb69ce2-e939-43fb-ad54-b97580a500ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from studio.research_assistant import analyst_graph, interview_graph, graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3429e3-0e29-4453-89f5-7021d130bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e97b61f-c28c-4d78-a0e0-7721c4c9d947",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(analyst_graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1f864fb-5a3d-423a-8454-a501e4c63253",
   "metadata": {},
   "source": [
    "max_analysts = 3 \n",
    "topic = \"The benefits of adopting LangGraph as an agent framework\"\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "analyst_response  = analyst_graph.invoke({\n",
    "    \"topic\": topic,\n",
    "    \"max_analysts\": max_analysts\n",
    "}, thread)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03686a35-48e3-405c-9546-7a749bcc1835",
   "metadata": {},
   "source": [
    "for analyst in analyst_response.get(\"analysts\"):\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a9fd6-85e9-475d-98c0-3fa029e646dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "max_analysts = 2\n",
    "topic = \"The benefits of adopting LangGraph as an agent framework\"\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in analyst_graph.stream({\"topic\":topic,\"max_analysts\":max_analysts,}, thread, stream_mode=\"values\"):\n",
    "    # Review\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96276c-244a-4caa-8c7d-ff50d8e9e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get state and look at next node\n",
    "state = analyst_graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7ad8a-6cac-4049-b5e3-26c3d59f3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We now update the state as if we are the human_feedback node\n",
    "analyst_graph.update_state(thread, {\"human_analysts_feedback\": \n",
    "                            \"Add in someone from a startup to add an entrepreneur perspective\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b534fe-8936-49f9-b47a-90603a8466a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the graph execution\n",
    "for event in analyst_graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    # Review\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664a733-6e17-44e1-b513-641e09e6981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we are satisfied, then we simply supply no feedback\n",
    "further_feedack = None\n",
    "analyst_graph.update_state(thread, {\"human_analyst_feedback\": \n",
    "                            further_feedack}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade9428-cb53-431c-9c97-10227dc53468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the graph execution to end\n",
    "for event in analyst_graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12702018-1a8e-4fa9-a33a-cda7a530e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = analyst_graph.get_state(thread)\n",
    "analysts = final_state.values.get('analysts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad1f22-0a15-48ea-b5d3-9dde7041b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyst in analysts:\n",
    "    print(f\"Name: {analyst.name}\")\n",
    "    print(f\"Affiliation: {analyst.affiliation}\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    print(f\"Description: {analyst.description}\")\n",
    "    print(\"-\" * 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf6c28-dc82-4f61-aee9-46b80a79f184",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(interview_graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b8e1c-8301-4caf-b69a-b27ba592f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from langchain_core.messages import  HumanMessage\n",
    "\n",
    "messages = [HumanMessage(f\"So you said you were writing an article on {topic}?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"100\"}}\n",
    "interview = interview_graph.invoke({\"analyst\": analysts[0], \"messages\": messages, \"max_num_turns\": 2}, thread)\n",
    "Markdown(interview['sections'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be4845-b067-4111-8ffa-913fe4550d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1b79a-8df0-4c1d-ba21-65b35a43fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "max_analysts = 3 \n",
    "topic = \"The benefits of adopting LangGraph as an agent framework\"\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream({\"topic\":topic,\n",
    "                           \"max_analysts\":max_analysts}, \n",
    "                          thread, \n",
    "                          stream_mode=\"values\"):\n",
    "    \n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e6a11-b05f-4f9d-b27f-ab9eb3a0dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now update the state as if we are the human_feedback node\n",
    "graph.update_state(thread, {\"human_analysts_feedback\": \n",
    "                                \"Add in the CEO of gen ai native startup\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f20db7-f3fd-4fa3-a86b-4bc2e67a4d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    analysts = event.get('analysts', '')\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee2ba7-9e51-470d-8ee3-dc2226bb6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm we are happy\n",
    "graph.update_state(thread, {\"human_analysts_feedback\": \n",
    "                            None}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d67049-a11e-4cbd-af44-e5e31601c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name = next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec449407-60cd-4ce2-aec9-4526b53fa7de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
