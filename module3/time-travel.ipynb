{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b68253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain-google-genai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af6dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "#from langchain.chat_models import init_chat_model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae664a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x: float, y:float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    " \n",
    "def subtract(x: float, y:float) -> float:\n",
    "    \"\"\"Subtract 'x' and 'y'.\"\"\"\n",
    "    return x - y\n",
    "\n",
    "\n",
    "def multiply(x: float, y:float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "\n",
    "def divide(x: float, y:float) -> float:\n",
    "    \"\"\"Divide 'x' and 'y'.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add, subtract, multiply, divide, exponentiate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533cd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    \"\"\"You are an helpful assistant tasked with performing arithmetic on a set of inputs.\n",
    "    \n",
    "    ----\n",
    "    User: 2 divide 3\n",
    "    AI: The answer is 0.66\n",
    "    \n",
    "    User: 20 divide -7\n",
    "    AI: The answer is -2.85\n",
    "    \n",
    "    User: 20 multiply 7\n",
    "    AI: The answer is 140.00    \n",
    "    \n",
    "    ----    \n",
    "    \n",
    "    \"\"\"\n",
    ") \n",
    "\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": llm_with_tools.invoke([sys_message] + state[\"messages\"])}\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([add, subtract, multiply, divide, exponentiate]))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "messages = graph.invoke({\n",
    "    \"messages\": HumanMessage(content = \"Multiply 2 and 3\")\n",
    "}, config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85603908",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0292da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states =[s for s in graph.get_state_history(config)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d081b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aea501",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8148a",
   "metadata": {},
   "source": [
    "## Replay Graph\n",
    "\n",
    "As we are passing *to_replay.config* it will run from that specific snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay = all_states[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d72e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9939ec2-8383-4a75-83ff-5d507b7f3de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18240a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2875fb44-cdba-42b1-8e25-e56f11a7ad44",
   "metadata": {},
   "source": [
    "## Forking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e702ca5-6c70-455a-a49c-af38cb0ee226",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751cc5a-42bf-4448-8d8d-37dce301e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fork = all_states[-2]\n",
    "to_fork.values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f36d8-8ddc-44cb-8749-b434851a4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fork.values[\"messages\"][0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7eda8e-bd60-4be7-a6cb-ab6db1b063e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9134d7f9-9563-4cd5-b7c3-2fbd6f1a0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fork.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b723a0-f717-4f4d-88e0-1f5260a406a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fork_config = graph.update_state(\n",
    "    to_fork.config,\n",
    "    {\"messages\": [HumanMessage(content='Multiply 5 and 3', \n",
    "                               id=to_fork.values[\"messages\"][0].id)]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d87d1a7-78c3-4bbf-b168-e196fe920dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fork_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf4e27-4069-4f91-b9db-bf28679f9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_states[0].values[\"messages\"])\n",
    "print(all_states[-1].values[\"messages\"])\n",
    "print(all_states[-2].values[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b7b28-7eba-4fd6-9b32-6b5f6f194e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states_new = [state for state in graph.get_state_history(config) ]\n",
    "print(all_states_new[0].values[\"messages\"])\n",
    "print(all_states_new[-1].values[\"messages\"])\n",
    "print(all_states_new[-2].values[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0111c21-d458-44e7-83e4-95a8dc2a984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states[0].values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04330d5c-9cb6-40b4-846b-3047e2eba8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_states_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3aa7ef-e0a8-467b-8638-b32a7fa8a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a838177-38aa-42ec-a1bc-1f718049ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, fork_config, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de389fb9-efb2-4e0a-a2c8-6922cc685ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
