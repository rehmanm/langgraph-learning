{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b68253",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain-google-genai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af6dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "#from langchain.chat_models import init_chat_model\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae664a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x: float, y:float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    " \n",
    "def subtract(x: float, y:float) -> float:\n",
    "    \"\"\"Subtract 'x' and 'y'.\"\"\"\n",
    "    return x - y\n",
    "\n",
    "\n",
    "def multiply(x: float, y:float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "\n",
    "def divide(x: float, y:float) -> float:\n",
    "    \"\"\"Divide 'x' and 'y'.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add, subtract, multiply, divide, exponentiate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533cd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    \"\"\"You are an helpful assistant tasked with performing arithmetic on a set of inputs.\n",
    "    \n",
    "    ----\n",
    "    User: 2 divide 3\n",
    "    AI: The answer is 0.66\n",
    "    \n",
    "    User: 20 divide -7\n",
    "    AI: The answer is -2.85\n",
    "    \n",
    "    User: 20 multiply 7\n",
    "    AI: The answer is 140.00    \n",
    "    \n",
    "    ----    \n",
    "    \n",
    "    \"\"\"\n",
    ") \n",
    "\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": llm_with_tools.invoke([sys_message] + state[\"messages\"])}\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([add, subtract, multiply, divide, exponentiate]))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ab3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "messages = graph.invoke({\n",
    "    \"messages\": HumanMessage(content = \"What is 2 ** 3\")\n",
    "}, config)\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85603908",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0292da",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states =[s for s in graph.get_state_history(config)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d081b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aea501",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay = all_states[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d72e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18240a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8148a",
   "metadata": {},
   "source": [
    "## Replay Graph\n",
    "\n",
    "As we are passing *to_replay.config* it will run from that specific snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ecdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
