{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30262fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f75ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def add(x: float, y:float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    " \n",
    "def subtract(x: float, y:float) -> float:\n",
    "    \"\"\"Subtract 'x' and 'y'.\"\"\"\n",
    "    return x - y\n",
    "\n",
    "\n",
    "def multiply(x: float, y:float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "\n",
    "def divide(x: float, y:float) -> float:\n",
    "    \"\"\"Divide 'x' and 'y'.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add, subtract, multiply, divide, exponentiate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    \"\"\"You are an helpful assistant tasked with performing arithmetic on a set of inputs.\n",
    "    \n",
    "    ----\n",
    "    User: 2 divide 3\n",
    "    AI: The answer is 0.66\n",
    "    \n",
    "    User: 20 divide -7\n",
    "    AI: The answer is -2.85\n",
    "    \n",
    "    User: 20 multiply 7\n",
    "    AI: The answer is 140.00    \n",
    "    \n",
    "    ----    \n",
    "    \n",
    "    \"\"\"\n",
    ") \n",
    "\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": llm_with_tools.invoke([sys_message] + state[\"messages\"])}\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([add, subtract, multiply, divide, exponentiate]))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory, interrupt_before=[\"tools\"])\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c05f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_input = {\n",
    "    \"messages\": \"Multiply 2 by 3\"\n",
    "}\n",
    "\n",
    "thread = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": \"1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_input = {\n",
    "    \"messages\": \"Multiply 2 by 3\"\n",
    "}\n",
    "\n",
    "thread = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": \"3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "\n",
    "user_approval = input(\"Do you want to call the tool? (yes/no): \")\n",
    "\n",
    "if user_approval.lower() == \"yes\":\n",
    "        \n",
    "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "        \n",
    "else:\n",
    "    print(\"user cancelled the operation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43183d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
