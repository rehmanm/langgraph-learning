{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf4480",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30262fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f75ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def add(x: float, y:float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    " \n",
    "def subtract(x: float, y:float) -> float:\n",
    "    \"\"\"Subtract 'x' and 'y'.\"\"\"\n",
    "    return x - y\n",
    "\n",
    "\n",
    "def multiply(x: float, y:float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "\n",
    "def divide(x: float, y:float) -> float:\n",
    "    \"\"\"Divide 'x' and 'y'.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add, subtract, multiply, divide, exponentiate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c143e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "sys_message = SystemMessage(\n",
    "    \"\"\"You are an helpful assistant tasked with performing arithmetic on a set of inputs.\n",
    "    \n",
    "    ----\n",
    "    User: 2 divide 3\n",
    "    AI: The answer is 0.66\n",
    "    \n",
    "    User: 20 divide -7\n",
    "    AI: The answer is -2.85\n",
    "    \n",
    "    User: 20 multiply 7\n",
    "    AI: The answer is 140.00    \n",
    "    \n",
    "    ----    \n",
    "    \n",
    "    \"\"\"\n",
    ") \n",
    "\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\": llm_with_tools.invoke([sys_message] + state[\"messages\"])}\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([add, subtract, multiply, divide, exponentiate]))\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory, interrupt_before=[\"assistant\"])\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c05f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_input = {\n",
    "    \"messages\": \"Multiply 2 by 3\"\n",
    "}\n",
    "\n",
    "thread = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": \"1\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(thread)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"messages\":[HumanMessage(content=\"No, actually multiply 3 by 3\")]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f68200",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state = graph.get_state(thread).values\n",
    "\n",
    "for m in new_state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71834790",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f05b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1bb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "\n",
    "from langgraph_sdk import get_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695711c-e65b-427a-b7fc-b3429014031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_client(url=URL)\n",
    "\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1b8d1-b27f-46e7-a13e-9638478010f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549078f-1666-4787-a909-33beb9c4597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = await client.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1179bd-9433-4ca5-a490-322668408a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "input_message = {\"messages\": [HumanMessage(content=\"Multiply 3 by 12\")]}\n",
    "\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input = input_message,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before = [\"assistant\"]\n",
    "):\n",
    "\n",
    "    messages = chunk.data.get(\"messages\", [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"---\"*50)\n",
    "\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832f15f2-2adf-40e9-abeb-6f174063870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc9e9fa-83a2-4aed-990c-c417c7f9f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastmessage = state[\"values\"][\"messages\"][-1]\n",
    "lastmessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969c81b-0b6a-4ab8-9665-a3441c1b90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastmessage[\"content\"] = \"No actually multiply 3 by 3\"\n",
    "lastmessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e73726-0fcc-40c3-8397-676669d56146",
   "metadata": {},
   "outputs": [],
   "source": [
    "await client.threads.update_state(thread[\"thread_id\"], {\"messages\": lastmessage})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b90926-7dc7-4531-8d67-6ab58aeed6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input = None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before = [\"assistant\"]\n",
    "):\n",
    "\n",
    "    messages = chunk.data.get(\"messages\", [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"---\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad4310-9417-443a-8316-371af8080e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    \"agent\",\n",
    "    input = None,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before = [\"assistant\"]\n",
    "):\n",
    "\n",
    "    messages = chunk.data.get(\"messages\", [])\n",
    "    if messages:\n",
    "        print(messages[-1])\n",
    "    print(\"---\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269cf68-48e4-4fae-97ef-5810e05ddbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Human Interupt\n",
    "\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "sys_message = SystemMessage(content=\"You are helpful assistant tasked with performing arithmatic on a set of input\")\n",
    "\n",
    "def human_feedback(state: MessagesState):\n",
    "    pass\n",
    "\n",
    "def assistant(state: MessagesState):\n",
    "    return {\"messages\":[llm_with_tools.invoke([sys_message]+state[\"messages\"])]}\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode([add, subtract, multiply, divide, exponentiate]))\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "builder.add_edge(START, \"human_feedback\")\n",
    "builder.add_edge(\"human_feedback\", \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    tools_condition\n",
    ")\n",
    "builder.add_edge(\"tools\", \"human_feedback\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959cc83-d54f-4bdb-9121-e03b94b9a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    \n",
    "# Get user input\n",
    "user_input = input(\"Tell me how you want to update the state: \")\n",
    "\n",
    "# We now update the state as if we are the human_feedback node\n",
    "graph.update_state(thread, {\"messages\": user_input}, as_node=\"human_feedback\")\n",
    "\n",
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdeb445-7e94-4581-9144-a1580ed4c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the graph execution\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab778475-0015-4ce3-8178-9d95ee288ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
